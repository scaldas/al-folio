<!DOCTYPE html>
<html lang="en">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Sebastian  Caldas


  | Publications

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<!-- 
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
 -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://scaldas.github.io/publications/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://scaldas.github.io/">
       <span class="font-weight-bold">Sebastian</span>   Caldas
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              Home
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                Publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <div class="publications">

<p>An up-to-date list is available on <a href="https://scholar.google.com/citations?user=u15oBdQAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar</a>.</p>

<h1> conferences &amp; journals </h1>
<ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MLHC</abbr>
    
  
  </div>

  <div id="caldas2021understanding" class="col-sm-8">
    
      <div class="title">Understanding Clinical Collaborations Through Federated Classifier Selection</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Sebastian Caldas</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Joo Heung Yoon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Michael R Pinsky,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gilles Clermont,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Artur Dubrawski
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Machine Learning for Healthcare Conference</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://proceedings.mlr.press/v149/caldas21a" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="https://proceedings.mlr.press/v149/caldas21a/caldas21a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
      
      <a href="/assets/pdf/frcls_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
      
    
    
      
      <a href="/assets/pdf/frcls_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a>
      
    
    
    
      <a href="https://www.youtube.com/watch?v=iqxFnpVACkc" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Talk</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deriving true clinical utility from models trained on multiple hospitals’ data is a key challenge in the adoption of Federated Learning (FL) systems in support of clinical collaborations. When utility is equated to predictive power, population heterogeneity between centers becomes a key bottleneck in training performant models. Nevertheless, there are other aspects to clinical utility that have frequently been overlooked in this context. Among them, we argue for the importance of understanding how a collaboration may be affecting the quality of a center’s predictions. Insights into how and when external knowledge is being useful can lead to strategic decisions by stakeholders, such as better allocation of local resources or even identifying best practices outside of the current organization. We take a step towards deriving such utility through FedeRated CLassifier Selection (FRCLS, pronounced “freckles”): an algorithm that reuses classifiers trained in outside institutions. It identifies regions of the feature space where the collaborators’ models will outperform the local center’s classifier, and can provide interpretable rules to describe these regions of beneficial expertise. We apply FRCLS to a sepsis prediction task in two different hospital systems, demonstrating its benefits in terms of understanding the types of patients for which the collaboration is useful and reasoning about the strategic decisions that may stem out of these analyses.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">AMIA</abbr>
    
  
  </div>

  <div id="caldas2021using" class="col-sm-8">
    
      <div class="title">Using Machine Learning to Support Transfer of Best Practices in Healthcare</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Sebastian Caldas</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jieshi Chen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Artur Dubrawski
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In AMIA Annual Symposium Proceedings</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The adoption of best practices has been shown to increase performance in healthcare institutions and is consistently demanded by both patients, payers, and external overseers. Nevertheless, transferring practices between healthcare organizations is a challenging and underexplored task. In this paper, we take a step towards enabling the transfer of best practices by identifying the likely beneficial opportunities for such transfer.  Specifically, we analyze the output of machine learning models trained at different organizations with the aims of (i) detecting the opportunity for the transfer of best practices, and (ii) providing a stop-gap solution while the actual transfer process takes place. We show the benefits of this methodology on a dataset of medical inpatient claims, demonstrating our ability to identify practice gaps and to support the transfer processes that address these gaps.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  </div>

  <div id="li2019differentially" class="col-sm-8">
    
      <div class="title">Differentially Private Meta-Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Jeffrey Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mikhail Khodak,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Sebastian Caldas</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Ameet Talwalkar
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Learning Representations</em>
      
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1909.05830" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
      <a href="https://openreview.net/forum?id=rJgqMRVYvr" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="https://arxiv.org/pdf/1909.05830.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Parameter-transfer is a well-known and versatile approach for meta-learning, with applications including few-shot learning, federated learning, and reinforcement learning. However, parameter-transfer algorithms often require sharing models that have been trained on the samples from specific tasks, thus leaving the task-owners susceptible to breaches of privacy. We conduct the first formal study of privacy in this setting and formalize the notion of task-global differential privacy as a practical relaxation of more commonly studied threat models. We then propose a new differentially private algorithm for gradient-based parameter transfer that not only satisfies this privacy requirement but also retains provable transfer learning guarantees in convex settings. Empirically, we apply our analysis to the problems of federated learning with personalization and few-shot classification, showing that allowing the relaxation to task-global privacy from the more commonly studied notion of local privacy leads to dramatically increased performance in recurrent neural language modeling and image classification.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>

<h1> workshops </h1>
<ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">FL-NeurIPS</abbr>
    
  
  </div>

  <div id="caldas2018expanding" class="col-sm-8">
    
      <div class="title">Expanding the reach of federated learning by reducing client resource requirements</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Sebastian Caldas</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jakub Konečny,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  H Brendan McMahan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Ameet Talwalkar
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Workshop on Federated Learning for Data Privacy and Confidentiality, FL-NeurIPS</em>
      
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1812.07210" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
      
      <a href="https://arxiv.org/pdf/1812.07210.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
      
      <a href="/assets/pdf/friendlyfl_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
      
    
    
      
      <a href="/assets/pdf/friendlyfl_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Communication on heterogeneous edge networks is a fundamental bottleneck in Federated Learning (FL), restricting both model capacity and user participation. To address this issue, we introduce two novel strategies to reduce communication costs: (1) the use of lossy compression on the global model sent server-to-client; and (2) Federated Dropout, which allows users to efficiently train locally on smaller subsets of the global model and also provides a reduction in both client-to-server communication and local computation. We empirically show that these strategies, combined with existing compression approaches for client-to-server communication, collectively provide up to a 14× reduction in server-to-client communication, a 1.7x reduction in local computation, and a 28× reduction in upload communication, all without degrading the quality of the final model. We thus comprehensively reduce FL’s impact on client device resources, allowing higher capacity models to be trained, and a more diverse set of users to be reached.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">FL-NeurIPS</abbr>
    
  
  </div>

  <div id="caldas2018leaf" class="col-sm-8">
    
      <div class="title">LEAF: A benchmark for federated settings</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Sebastian Caldas</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sai Meher Karthik Duddu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Peter Wu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tian Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jakub Konečnỳ,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  H Brendan McMahan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Virginia Smith,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Ameet Talwalkar
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Workshop on Federated Learning for Data Privacy and Confidentiality, FL-NeurIPS</em>
      
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1812.01097" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
      
      <a href="https://arxiv.org/pdf/1812.01097.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
      <a href="https://github.com/TalwalkarLab/leaf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
      
      <a href="/assets/pdf/leaf_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
      
    
    
    
      <a href="https://leaf.cmu.edu" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Modern federated networks, such as those comprised of wearable devices, mobile phones, or autonomous vehicles, generate massive amounts of data each day. This wealth of data can help to learn models that can improve the user experience on each device. However, the scale and heterogeneity of federated data presents new challenges in research areas such as federated learning, meta-learning, and multi-task learning. As the machine learning community begins to tackle these challenges, we are at a critical time to ensure that developments made in these areas are grounded with realistic benchmarks. To this end, we propose LEAF, a modular benchmarking framework for learning in federated settings. LEAF includes a suite of open-source federated datasets, a rigorous evaluation framework, and a set of reference implementations, all geared towards capturing the obstacles and intricacies of practical federated environments.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SysML</abbr>
    
  
  </div>

  <div id="caldas2018federated" class="col-sm-8">
    
      <div class="title">Federated kernelized multi-task learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Sebastian Caldas</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Virginia Smith,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Ameet Talwalkar
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>SysML Conf</em>
      
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://mlsys.org/Conferences/2019/doc/2018/30.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
      
      <a href="/assets/pdf/fedkmtl_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
      
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Federated learning poses new statistical and systems challenges in the training of machine learning models over distributed networks of devices. In this ongoing work, we develop a state of the art MTL federated system that bypasses the modelling limitations of previous efforts through the inclusion of non-linear mappings in its formulation. We address the new issues that arise due to this inclusion and that are associated with the particulars of the federated scenario, such as communication and storage costs, introducing this way the first fully practical kernelized federated framework.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>

</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    © Copyright 2023 Sebastian  Caldas.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Scramble Script by Jeff Donahue -->
<script src="/assets/js/scramble.js"></script>
  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
